Awesome 🎉 glad you got it working!
Here’s a clean **summary of all the commands + short explanations** from our session so you can store them for future reference:

---

## 🔧 Zeek Setup & Run

```bash
# Run Zeek with JSON output
sudo /opt/zeek/bin/zeek -i s1-eth1 LogAscii::use_json=T LogAscii::json_timestamps=JSON::TS_MILLIS
```

👉 Captures traffic on `s1-eth1`, writes `conn.log` in JSON format.

---

## 🌐 Mininet Setup

```bash
# Start Mininet with 1 switch and 2 hosts
sudo mn --topo single,2 --mac --switch ovsk --controller remote
```

👉 Creates `h1`, `h2`, and switch `s1` with interfaces `s1-eth1`, `s1-eth2`.

```bash
# Inside Mininet CLI
h2 python3 -m http.server 8000 &       # Start HTTP server on h2
h1 curl -s http://h2:8000 > /dev/null  # Request page from h2
h1 ping -c 5 h2                        # Ping test from h1 → h2
```

---

## 📑 Prepare Data for Dry-Run

```bash
# Extract one flow from conn.log for testing
head -n 1 conn.log > one_conn.jsonl
```

👉 Needed so preprocessing script has a single JSON record to test.

---

## 🐍 Preprocessing & Scaling (Python)

```python
# Load Zeek flow + expected feature order + scaler
with open("one_conn.jsonl") as f:
    zeek_flow = json.loads(f.readline().strip())

with open("expected_features.json") as f:
    expected_features = json.load(f)

scaler = joblib.load("scaler_pipeline.joblib")

# Build raw vector → scale
raw_vector = build_feature_vector(zeek_flow, expected_features)
scaled_vector = scaler.transform([raw_vector])

# Reshape for Conv1D input (batch, timesteps, channels)
scaled_vector = np.expand_dims(scaled_vector, axis=-1)   # (1, 77, 1)

# Send to TF-Serving
url = "http://<WINDOWS_IP>:8501/v1/models/<MODEL_NAME>:predict"
payload = {"instances": scaled_vector.tolist()}
response = requests.post(url, json=payload)
print(response.json())
```

---

## 📡 Network & TF-Serving Check

```bash
# From Windows, check model server locally
curl http://localhost:8501/v1/models/<MODEL_NAME>

# From Ubuntu, check connectivity to Windows TF-Serving
curl http://<WINDOWS_IP>:8501/v1/models/<MODEL_NAME>
```

👉 Confirms TF-Serving is running and reachable.

---

⚡ That’s the full set of **core commands & steps** you used:

1. Run Zeek with JSON logging
2. Start Mininet with 2 hosts
3. Generate traffic (HTTP + ping)
4. Extract one flow from `conn.log`
5. Preprocess + scale → reshape → send to TF-Serving
6. Verify TF-Serving connectivity

---

Do you want me to also include the **Zeek → feature mapping table** (like `id.resp_p → destinationport`, `duration → flowduration`, etc.) so you have a reference for how to build all 77 features?

